{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Python path to ensure correct imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path to allow importing from parent directory\n",
    "current_dir = Path(os.path.abspath('')).parent\n",
    "if str(current_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(current_dir))\n",
    "\n",
    "print(\"Path fixed for imports. Working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57c8e3",
   "metadata": {},
   "source": [
    "# Financial Agents System - Merged Implementation\n",
    "\n",
    "This file combines three financial agent components into a single integrated system:\n",
    "\n",
    "1. Knowledge Agent: Retrieves information about financial products\n",
    "2. Card Agent: Executes card-related actions (activate, deactivate)\n",
    "3. Orchestrator Agent: Coordinates between the other agents based on user intent\n",
    "\n",
    "Each component is fully defined with its own state types, functions, and graph workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c0471",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "from typing import TypedDict, Annotated, Sequence, Dict, Any, List, Optional, Literal\n",
    "from pathlib import Path\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "# Environment variable loading\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "CHROMA_HOST = os.environ.get(\"CHROMA_HOST\", \"localhost\")\n",
    "CHROMA_PORT = int(os.environ.get(\"CHROMA_PORT\", \"8000\"))\n",
    "CHROMA_PERSIST_DIRECTORY = os.environ.get(\"CHROMA_PERSIST_DIRECTORY\", \n",
    "                                         os.path.join(Path(os.path.abspath(\"\")), \"data\", \"chroma_db\"))\n",
    "USE_PERSISTENT = os.environ.get(\"CHROMA_USE_PERSISTENT\", \"true\").lower() == \"true\"\n",
    "COLLECTION_NAME = \"healthcare_financial_data\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "LLM_MODEL = \"gpt-4-turbo\"\n",
    "DATA_DIR = os.path.join(Path(os.path.abspath(\"\")), 'data')\n",
    "# Card API configuration\n",
    "CARD_API_BASE_URL = \"http://card-api:8080/api/cards\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e79736",
   "metadata": {},
   "source": [
    "## Using Docker service name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Docker service name\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea17935",
   "metadata": {},
   "source": [
    "## Vecotor DB Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520beae1",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c57ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_vectorization():\n",
    "    \"\"\"\n",
    "    Load financial and healthcare data for vector db ingestion\n",
    "    \"\"\"\n",
    "    data_sources = []\n",
    "    \n",
    "    # Load accounts data\n",
    "    accounts_file = os.path.join(DATA_DIR, 'synthetic_healthcare_accounts.csv')\n",
    "    if os.path.exists(accounts_file):\n",
    "        logger.info(f\"Loading accounts data from {accounts_file}\")\n",
    "        try:\n",
    "            accounts_df = pd.read_csv(accounts_file)\n",
    "            accounts_text = accounts_df.to_csv(index=False)\n",
    "            data_sources.append({\n",
    "                \"content\": accounts_text,\n",
    "                \"metadata\": {\"source\": \"healthcare_accounts\"}\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load accounts data: {e}\")\n",
    "    \n",
    "    # Load transactions data\n",
    "    transactions_file = os.path.join(DATA_DIR, 'synthetic_healthcare_transactions.csv')\n",
    "    if os.path.exists(transactions_file):\n",
    "        logger.info(f\"Loading transactions data from {transactions_file}\")\n",
    "        try:\n",
    "            transactions_df = pd.read_csv(transactions_file)\n",
    "            # Take a sample if it's too large\n",
    "            if len(transactions_df) > 10000:\n",
    "                transactions_df = transactions_df.sample(10000)\n",
    "            transactions_text = transactions_df.to_csv(index=False)\n",
    "            data_sources.append({\n",
    "                \"content\": transactions_text,\n",
    "                \"metadata\": {\"source\": \"healthcare_transactions\"}\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load transactions data: {e}\")\n",
    "    \n",
    "    # Load product data\n",
    "    products_file = os.path.join(DATA_DIR, 'synthetic_healthcare_products.json')\n",
    "    if os.path.exists(products_file):\n",
    "        logger.info(f\"Loading products data from {products_file}\")\n",
    "        try:\n",
    "            with open(products_file, 'r') as f:\n",
    "                products_data = json.load(f)\n",
    "                # Process each product separately for better chunks\n",
    "                for product in products_data.get(\"products\", []):\n",
    "                    product_text = json.dumps(product, indent=2)\n",
    "                    data_sources.append({\n",
    "                        \"content\": product_text,\n",
    "                        \"metadata\": {\n",
    "                            \"source\": \"healthcare_products\",\n",
    "                            \"product_id\": product.get(\"id\", \"\"),\n",
    "                            \"product_name\": product.get(\"name\", \"\")\n",
    "                        }\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load products data: {e}\")\n",
    "    \n",
    "    # Load plans data\n",
    "    plans_file = os.path.join(DATA_DIR, 'synthetic_healthcare_plans.json')\n",
    "    if os.path.exists(plans_file):\n",
    "        logger.info(f\"Loading plans data from {plans_file}\")\n",
    "        try:\n",
    "            with open(plans_file, 'r') as f:\n",
    "                plans_data = json.load(f)\n",
    "                plans_text = json.dumps(plans_data, indent=2)\n",
    "                data_sources.append({\n",
    "                    \"content\": plans_text,\n",
    "                    \"metadata\": {\"source\": \"healthcare_plans\"}\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load plans data: {e}\")\n",
    "    \n",
    "    return data_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "print(f\"Data directory path: {DATA_DIR}\")\n",
    "data_sources = load_data_for_vectorization()\n",
    "print(f\"Loaded {len(data_sources)} data sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b9e38",
   "metadata": {},
   "source": [
    "### 2. Data chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(data_sources):\n",
    "    \"\"\"\n",
    "    Create optimally sized chunks from the data sources\n",
    "    \"\"\"\n",
    "    # Constants for chunking\n",
    "    CHUNK_SIZE = 600\n",
    "    CHUNK_OVERLAP = 90  # 15% of chunk size\n",
    "    \n",
    "    logger.info(f\"Creating chunks with size={CHUNK_SIZE}, overlap={CHUNK_OVERLAP}\")\n",
    "    \n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    \n",
    "    # Process each data source\n",
    "    for source in data_sources:\n",
    "        content = source[\"content\"]\n",
    "        metadata = source[\"metadata\"]\n",
    "        \n",
    "        # Split the text into chunks\n",
    "        texts = text_splitter.split_text(content)\n",
    "        \n",
    "        # Create documents for each chunk\n",
    "        for i, text in enumerate(texts):\n",
    "            # Enrich metadata with chunk information\n",
    "            chunk_metadata = metadata.copy()\n",
    "            chunk_metadata[\"chunk_id\"] = i\n",
    "            chunk_metadata[\"chunk_count\"] = len(texts)\n",
    "            \n",
    "            all_chunks.append({\"text\": text, \"metadata\": chunk_metadata})\n",
    "    \n",
    "    logger.info(f\"Created {len(all_chunks)} chunks from {len(data_sources)} data sources\")\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function (only if data_sources is not empty)\n",
    "if data_sources:\n",
    "    chunks = create_chunks(data_sources)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    \n",
    "    # Display a sample chunk\n",
    "    if chunks:\n",
    "        sample_chunk = chunks[0]\n",
    "        print(\"\\nSample chunk metadata:\")\n",
    "        print(sample_chunk[\"metadata\"])\n",
    "        print(\"\\nSample chunk text (first 100 chars):\")\n",
    "        print(sample_chunk[\"text\"][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110bb9d4",
   "metadata": {},
   "source": [
    "### 3. Get embeddings client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_client():\n",
    "    \"\"\"\n",
    "    Get the OpenAI embeddings client\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        logger.error(\"OPENAI_API_KEY environment variable is not set\")\n",
    "        print(\"⚠️ Error: OPENAI_API_KEY is not set. Please set it in your environment.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=EMBEDDING_MODEL,\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        logger.info(\"Successfully initialized OpenAI embeddings client\")\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize embeddings client: {e}\")\n",
    "        print(f\"⚠️ Error initializing OpenAI embeddings: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "embeddings_client = get_embedding_client()\n",
    "if embeddings_client:\n",
    "    print(\"✅ Successfully initialized OpenAI embeddings client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa69bd",
   "metadata": {},
   "source": [
    "### 4. Vector store setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store():\n",
    "    \"\"\"\n",
    "    Get or create the ChromaDB vector store with our healthcare financial data\n",
    "    \"\"\"\n",
    "    # Check if we have a flag file indicating the vector store has been populated\n",
    "    flag_file = os.path.join(DATA_DIR, 'vector_store_populated.flag')\n",
    "    \n",
    "    # Get embeddings client\n",
    "    embeddings = get_embedding_client()\n",
    "    if not embeddings:\n",
    "        logger.error(\"Cannot get vector store - embeddings client initialization failed\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize the vector store\n",
    "    try:\n",
    "        vector_store = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=CHROMA_PERSIST_DIRECTORY if USE_PERSISTENT else None,\n",
    "            client_settings=chromadb.config.Settings(\n",
    "                chroma_api_impl=\"duckdb+parquet\",\n",
    "                chroma_server_host=CHROMA_HOST if not USE_PERSISTENT else None,\n",
    "                chroma_server_http_port=CHROMA_PORT if not USE_PERSISTENT else None,\n",
    "                anonymized_telemetry=False\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # If flag exists, return the existing vector store\n",
    "        if os.path.exists(flag_file):\n",
    "            logger.info(\"Using existing vector store\")\n",
    "            print(f\"✅ Using existing vector store from {CHROMA_PERSIST_DIRECTORY}\")\n",
    "            return vector_store\n",
    "        \n",
    "        # Otherwise, populate the vector store\n",
    "        logger.info(\"Populating vector store with healthcare financial data\")\n",
    "        print(\"⏳ Populating new vector store - this may take a while...\")\n",
    "        \n",
    "        # Load and chunk data if not already done\n",
    "        nonlocal data_sources, chunks\n",
    "        if 'data_sources' not in locals():\n",
    "            data_sources = load_data_for_vectorization()\n",
    "        \n",
    "        if 'chunks' not in locals() or not chunks:\n",
    "            chunks = create_chunks(data_sources)\n",
    "        \n",
    "        # Populate vector store with chunks\n",
    "        for chunk in chunks:\n",
    "            vector_store.add_texts(\n",
    "                texts=[chunk[\"text\"]],\n",
    "                metadatas=[chunk[\"metadata\"]]\n",
    "            )\n",
    "        \n",
    "        # Persist if using persistent mode\n",
    "        if USE_PERSISTENT:\n",
    "            vector_store.persist()\n",
    "        \n",
    "        # Create flag file\n",
    "        with open(flag_file, 'w') as f:\n",
    "            f.write(\"Vector store populated on \" + pd.Timestamp.now().isoformat())\n",
    "        \n",
    "        logger.info(f\"Vector store populated with {len(chunks)} chunks\")\n",
    "        print(f\"✅ Vector store populated with {len(chunks)} chunks\")\n",
    "        return vector_store\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize vector store: {e}\")\n",
    "        print(f\"⚠️ Error initializing vector store: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test vector store\n",
    "try:\n",
    "    vector_store = get_vector_store()\n",
    "    \n",
    "    if vector_store:\n",
    "        # Test with a simple query\n",
    "        query = \"What are HSA accounts?\"\n",
    "        results = vector_store.similarity_search(query, k=2)\n",
    "        \n",
    "        print(f\"\\n✅ Vector store is working! Found {len(results)} results for query: '{query}'\")\n",
    "        \n",
    "        # Display first result\n",
    "        if results:\n",
    "            print(\"\\nFirst result:\")\n",
    "            print(f\"Content: {results[0].page_content[:150]}...\")\n",
    "            print(f\"Metadata: {results[0].metadata}\")\n",
    "    else:\n",
    "        print(\"⚠️ Vector store initialization failed\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error testing vector store: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb513b3",
   "metadata": {},
   "source": [
    "## Knowledge Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Knowledge Agent State ---\n",
    "class KnowledgeAgentState(TypedDict):\n",
    "    query: str\n",
    "    search_results: List[Dict[str, Any]]\n",
    "    response: str\n",
    "    error: Optional[str]\n",
    "    account_types: List[str]\n",
    "    intent: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5026610",
   "metadata": {},
   "source": [
    "## Knowledge Agent Node Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Knowledge Agent Node Functions ---\n",
    "def retrieve_knowledge(state: KnowledgeAgentState) -> KnowledgeAgentState:\n",
    "    \"\"\"Retrieves relevant knowledge from the vector database based on the query.\"\"\"\n",
    "    logger.info(f\"Retrieving knowledge for query: {state['query']}\")\n",
    "    query = state['query']\n",
    "    search_results = []\n",
    "    error = None\n",
    "    # Identify account types mentioned in the query\n",
    "    account_types = []\n",
    "    for account_type in [\"HSA\", \"FSA\", \"Health Savings Account\", \"Flexible Spending Account\", \n",
    "                       \"Dependent Care\", \"Prepaid\", \"Health Care Spend\"]:\n",
    "        if account_type.lower() in query.lower():\n",
    "            short_type = account_type\n",
    "            if account_type == \"Health Savings Account\":\n",
    "                short_type = \"HSA\"\n",
    "            elif account_type == \"Flexible Spending Account\":\n",
    "                short_type = \"FSA\"\n",
    "            if short_type not in account_types:\n",
    "                account_types.append(short_type)\n",
    "    # Get vector store\n",
    "    vector_store = get_vector_store()\n",
    "    try:\n",
    "        if vector_store:\n",
    "            # Enhance query with account types if specified\n",
    "            enhanced_query = query\n",
    "            if account_types:\n",
    "                account_types_str = \", \".join(account_types)\n",
    "                enhanced_query = f\"{query} relevant to {account_types_str}\"\n",
    "            # Perform vector search\n",
    "            docs = vector_store.similarity_search(enhanced_query, k=5)\n",
    "            # Process search results\n",
    "            for doc in docs:\n",
    "                search_results.append({\n",
    "                    \"text\": doc.page_content,\n",
    "                    \"source\": doc.metadata.get(\"source\", \"unknown\"),\n",
    "                    \"product_id\": doc.metadata.get(\"product_id\", \"\"),\n",
    "                    \"product_name\": doc.metadata.get(\"product_name\", \"\")\n",
    "                })\n",
    "            logger.info(f\"Found {len(search_results)} search results\")\n",
    "        else:\n",
    "            # Fallback to mock data if vector store is not available\n",
    "            logger.warning(\"Vector store not available. Using mock data.\")\n",
    "            # Mock results based on query\n",
    "            if \"hsa\" in query.lower() or \"health savings\" in query.lower():\n",
    "                search_results.append({\n",
    "                    \"text\": \"Health Savings Account (HSA) is a tax-advantaged savings account for individuals with high-deductible health plans. The 2024 contribution limit for individuals is $4,150 and for families is $8,300.\",\n",
    "                    \"source\": \"healthcare_products\",\n",
    "                    \"product_id\": \"HSA001\",\n",
    "                    \"product_name\": \"Health Savings Account (HSA)\"\n",
    "                })\n",
    "            elif \"fsa\" in query.lower() or \"flexible spending\" in query.lower():\n",
    "                search_results.append({\n",
    "                    \"text\": \"Flexible Spending Account (FSA) is an employer-sponsored account allowing employees to set aside pre-tax dollars for eligible healthcare expenses. The 2024 contribution limit is $3,200.\",\n",
    "                    \"source\": \"healthcare_products\",\n",
    "                    \"product_id\": \"FSA001\",\n",
    "                    \"product_name\": \"Flexible Spending Account (FSA)\"\n",
    "                })\n",
    "            else:\n",
    "                search_results.append({\n",
    "                    \"text\": \"Healthcare financial products include HSAs, FSAs, Dependent Care accounts, and Prepaid cards. Each has different eligibility requirements and benefits.\",\n",
    "                    \"source\": \"healthcare_products\",\n",
    "                    \"product_id\": \"\",\n",
    "                    \"product_name\": \"\"\n",
    "                })\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during knowledge retrieval: {e}\")\n",
    "        error = f\"Failed to retrieve knowledge: {e}\"\n",
    "        search_results = []\n",
    "    # Classify query intent\n",
    "    intent = classify_intent(query)\n",
    "    return {\n",
    "        **state, \n",
    "        \"search_results\": search_results, \n",
    "        \"error\": error,\n",
    "        \"account_types\": account_types,\n",
    "        \"intent\": intent\n",
    "    }\n",
    "def classify_intent(query: str) -> str:\n",
    "    \"\"\"Classify the intent of the query.\"\"\"\n",
    "    try:\n",
    "        # Use OpenAI to classify intent\n",
    "        completion = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an intent classifier for healthcare financial queries.\n",
    "                    Classify the user's intent into one of these categories:\n",
    "                    - INFORMATION: General question about healthcare financial products\n",
    "                    - COMPARISON: Comparing different healthcare account types\n",
    "                    - ELIGIBILITY: Questions about eligibility for specific accounts\n",
    "                    - CONTRIBUTION: Questions about contribution limits or rules\n",
    "                    - SPENDING: Questions about spending rules or eligible expenses\n",
    "                    - OTHER: Any other intent\n",
    "                    Return ONLY the intent category, nothing else.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        intent = completion.choices[0].message.content.strip()\n",
    "        # Normalize the intent\n",
    "        for valid_intent in [\"INFORMATION\", \"COMPARISON\", \"ELIGIBILITY\", \"CONTRIBUTION\", \"SPENDING\", \"OTHER\"]:\n",
    "            if valid_intent in intent:\n",
    "                return valid_intent\n",
    "        return \"OTHER\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error classifying intent: {e}\")\n",
    "        return \"OTHER\"\n",
    "def generate_response(state: KnowledgeAgentState) -> KnowledgeAgentState:\n",
    "    \"\"\"Generates a response based on the retrieved knowledge using OpenAI.\"\"\"\n",
    "    logger.info(\"Generating response\")\n",
    "    if state['error']:\n",
    "        return {**state, \"response\": f\"Sorry, I encountered an error: {state['error']}\"}\n",
    "    if not state['search_results']:\n",
    "        return {**state, \"response\": \"I couldn't find specific information for your query.\"}\n",
    "    query = state['query']\n",
    "    account_types = state.get('account_types', [])\n",
    "    intent = state.get('intent', 'OTHER')\n",
    "    # Construct context from search results\n",
    "    context_parts = []\n",
    "    for i, result in enumerate(state['search_results']):\n",
    "        source_info = f\" (Source: {result['source']})\"\n",
    "        if result['product_name']:\n",
    "            source_info += f\" (Product: {result['product_name']})\"\n",
    "        context_parts.append(f\"Result {i+1}: {result['text']}{source_info}\")\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    # Prepare prompt for response generation\n",
    "    prompt_template = \"\"\"You are a healthcare financial expert assistant. \n",
    "    Answer the following question based on the context provided.\n",
    "    Context:\n",
    "    {context}\n",
    "    User's question: {query}\n",
    "    Account types mentioned: {account_types}\n",
    "    Intent: {intent}\n",
    "    Give a clear, concise, and accurate answer based on the context. If the context doesn't contain the answer, \n",
    "    acknowledge that you don't have enough information rather than making up an answer.\n",
    "    Focus on providing factual information relevant to healthcare financial accounts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate response\n",
    "        completion = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt_template.format(\n",
    "                    context=context,\n",
    "                    query=query,\n",
    "                    account_types=\", \".join(account_types) if account_types else \"None specifically mentioned\",\n",
    "                    intent=intent\n",
    "                )},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        logger.info(f\"Generated response: {response[:100]}...\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during OpenAI completion: {e}\")\n",
    "        response = f\"Sorry, I encountered an error while generating the response: {e}\"\n",
    "        state['error'] = str(e)  # Store the error\n",
    "    return {**state, \"response\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d029d7e",
   "metadata": {},
   "source": [
    "## Knowledge Agent Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Knowledge Agent Graph Definition ---\n",
    "knowledge_workflow = StateGraph(KnowledgeAgentState)\n",
    "# Add nodes\n",
    "knowledge_workflow.add_node(\"retrieve\", retrieve_knowledge)\n",
    "knowledge_workflow.add_node(\"generate\", generate_response)\n",
    "# Define edges\n",
    "knowledge_workflow.set_entry_point(\"retrieve\")\n",
    "knowledge_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "knowledge_workflow.add_edge(\"generate\", END)\n",
    "# Compile graph\n",
    "knowledge_agent = knowledge_workflow.compile()\n",
    "def handle_query(query: str) -> str:\n",
    "    \"\"\"Handle a user query and return a response.\"\"\"\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"search_results\": [],\n",
    "        \"response\": \"\",\n",
    "        \"error\": None,\n",
    "        \"account_types\": [],\n",
    "        \"intent\": None\n",
    "    }\n",
    "    try:\n",
    "        result = knowledge_agent.invoke(initial_state)\n",
    "        return result[\"response\"]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing query: {e}\")\n",
    "        return f\"An error occurred while processing your query: {str(e)}\"\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3951c",
   "metadata": {},
   "source": [
    "## Card Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Card Agent State ---\n",
    "class CardAgentState(TypedDict):\n",
    "    action: str # e.g., \"activate\", \"deactivate\"\n",
    "    card_number: str # The last four digits of the card\n",
    "    parameters: dict # Any additional parameters needed for the API call\n",
    "    api_response: dict | None # Response from the card API\n",
    "    confirmation_message: str # User-facing message\n",
    "    error: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87524765",
   "metadata": {},
   "source": [
    "## Card Agent Tool (API Call Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a00e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Card Agent Tool (API Call Function) ---\n",
    "def call_card_api(action: str, card_number: str, parameters: dict) -> dict:\n",
    "    \"\"\"Calls the Card Service API.\"\"\"\n",
    "    url = f\"{CARD_API_BASE_URL}/{action}\"\n",
    "    payload = {\"cardLastFour\": card_number, **parameters}\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers={'Content-Type': 'application/json'}, timeout=10)\n",
    "        api_data = response.json() if response.content else {\"message\": \"No content\"}\n",
    "        if response.ok:\n",
    "            return {\"success\": True, **api_data}\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"message\": api_data.get(\"message\", f\"Error {response.status_code}\"),\n",
    "            \"status_code\": response.status_code,\n",
    "            \"api_response\": api_data\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"message\": f\"API error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9d4e3",
   "metadata": {},
   "source": [
    "## Card Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a276526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Card Agent Nodes ---\n",
    "def execute_card_action(state: CardAgentState) -> CardAgentState:\n",
    "    \"\"\"Executes the requested card action by calling the API.\"\"\"\n",
    "    api_result = call_card_api(state['action'], state['card_number'], state['parameters'])\n",
    "    if api_result.get(\"success\"):\n",
    "        confirmation_message = api_result.get(\"message\", f\"Card {state['action']} processed successfully.\")\n",
    "    else:\n",
    "        confirmation_message = f\"Failed to {state['action']} card. Error: {api_result.get('message')}\"\n",
    "    return {\n",
    "        **state, \n",
    "        \"api_response\": api_result, \n",
    "        \"confirmation_message\": confirmation_message, \n",
    "        \"error\": None if api_result.get(\"success\") else api_result.get(\"message\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a915",
   "metadata": {},
   "source": [
    "## Card Agent Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Card Agent Graph Definition ---\n",
    "card_workflow = StateGraph(CardAgentState)\n",
    "# Add node\n",
    "card_workflow.add_node(\"execute\", execute_card_action)\n",
    "# Define edges\n",
    "card_workflow.set_entry_point(\"execute\")\n",
    "card_workflow.add_edge(\"execute\", END)\n",
    "# Compile graph\n",
    "card_agent_app = card_workflow.compile()\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85025501",
   "metadata": {},
   "source": [
    "## Orchestrator State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24678a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestrator State ---\n",
    "class OrchestratorState(TypedDict):\n",
    "    user_query: str\n",
    "    intent: Literal[\"knowledge\", \"card_action\", \"unknown\", \"error\"]\n",
    "    card_action_details: CardAgentState | None # Details needed for card agent\n",
    "    knowledge_agent_response: str | None\n",
    "    card_agent_response: str | None\n",
    "    final_response: str\n",
    "    error: str | None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1118b76",
   "metadata": {},
   "source": [
    "## Orchestrator Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586df191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestrator Nodes ---\n",
    "def classify_intent(state: OrchestratorState) -> OrchestratorState:\n",
    "    \"\"\"Classifies the user's intent using OpenAI.\"\"\"\n",
    "    print(f\"--- Orchestrator: Classifying intent for query: {state['user_query']} ---\")\n",
    "    query = state['user_query']\n",
    "    intent = \"unknown\"\n",
    "    error = None\n",
    "    card_action_details = None\n",
    "    # Initialize response fields to None\n",
    "    knowledge_agent_response = None\n",
    "    card_agent_response = None\n",
    "    prompt = f\"\"\"Classify the user's intent based on their query. Choose one: 'knowledge', 'card_action', or 'unknown'.\n",
    "    - 'knowledge': User is asking for information (e.g., 'What is an HSA?', 'Tell me about prepaid cards').\n",
    "    - 'card_action': User wants to perform an action on a card (e.g., 'Activate my card', 'Deactivate card ending in 1234').\n",
    "    - 'unknown': The intent is unclear or not related to finance/cards.\n",
    "    If the intent is 'card_action', extract the following information in JSON format:\n",
    "    - \"intent\": \"card_action\"\n",
    "    - \"action\": The action to perform (e.g., \"activate\", \"deactivate\")\n",
    "    - \"card_identifier\": Card number or last 4 digits\n",
    "    - \"parameters\": A dictionary of additional parameters like:\n",
    "        - \"cvv\": Card CVV (if provided)\n",
    "        - \"expiryDate\": Card expiry date in format MM/YY (if provided)\n",
    "        - \"reason\": Reason for deactivation (if provided)\n",
    "    For example, if the user says \"I want to activate my card ending in 4444 with CVV 123 and expiry date 05/26\",\n",
    "    you should return:\n",
    "    {{\"intent\": \"card_action\", \"action\": \"activate\", \"card_identifier\": \"4444\", \"parameters\": {{\"cvv\": \"123\", \"expiryDate\": \"05/26\"}}}}\n",
    "    If the intent is 'knowledge' or 'unknown', format as JSON: {{\"intent\": \"...\"}}\n",
    "    User Query: \"{query}\"\n",
    "    JSON Output:\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\", # Use a model suitable for classification\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an intent classification expert for financial services.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"} # Request JSON output if model supports\n",
    "        )\n",
    "        result_json = json.loads(completion.choices[0].message.content)\n",
    "        intent = result_json.get(\"intent\", \"unknown\")\n",
    "        print(f\"Classified intent: {intent}\")\n",
    "        if intent == \"card_action\":\n",
    "            action = result_json.get(\"action\")\n",
    "            card_identifier = result_json.get(\"card_identifier\")\n",
    "            parameters = result_json.get(\"parameters\", {})\n",
    "            # Print the extracted parameters for debugging\n",
    "            print(f\"Extracted parameters: {parameters}\")\n",
    "            if action and card_identifier:\n",
    "                # In a real system, you'd need more robust extraction and potentially clarification\n",
    "                card_action_details = {\n",
    "                    \"action\": action,\n",
    "                    \"card_number\": card_identifier, # May need validation/lookup\n",
    "                    \"parameters\": parameters,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eacb2",
   "metadata": {},
   "source": [
    "## Orchestrator Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestrator Conditional Edges ---\n",
    "def decide_route(state: OrchestratorState) -> Literal[\"knowledge\", \"card_action\", \"end_error\", \"end_unknown\"]:\n",
    "    \"\"\"Determines the next step based on the classified intent.\"\"\"\n",
    "    print(f\"--- Orchestrator: Deciding route based on intent: {state['intent']} ---\")\n",
    "    if state.get('error') and state['intent'] == 'error':\n",
    "        return \"end_error\"\n",
    "    elif state['intent'] == 'knowledge':\n",
    "        return \"knowledge\"\n",
    "    elif state['intent'] == 'card_action':\n",
    "        if state['card_action_details']: # Check if details were extracted\n",
    "             return \"card_action\"\n",
    "        else:\n",
    "             print(\"Routing to end_unknown due to missing card details despite intent.\")\n",
    "             return \"end_unknown\" # Treat as unknown if details missing\n",
    "    else: # unknown\n",
    "        return \"end_unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4103bb7",
   "metadata": {},
   "source": [
    "## Orchestrator Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Orchestrator Graph Definition ---\n",
    "workflow = StateGraph(OrchestratorState)\n",
    "# Add nodes\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "workflow.add_node(\"knowledge_agent\", route_to_knowledge_agent)\n",
    "workflow.add_node(\"card_agent\", route_to_card_agent)\n",
    "workflow.add_node(\"format_response\", format_final_response)\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"classify_intent\")\n",
    "# Conditional routing after classification\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify_intent\",\n",
    "    decide_route,\n",
    "    {\n",
    "        \"knowledge\": \"knowledge_agent\",\n",
    "        \"card_action\": \"card_agent\",\n",
    "        \"end_error\": \"format_response\", # Go directly to formatting for critical errors\n",
    "        \"end_unknown\": \"format_response\" # Go directly to formatting for unknown intent\n",
    "    }\n",
    ")\n",
    "# Edges from agents to final formatting\n",
    "workflow.add_edge(\"knowledge_agent\", \"format_response\")\n",
    "workflow.add_edge(\"card_agent\", \"format_response\")\n",
    "# End after formatting\n",
    "workflow.add_edge(\"format_response\", END)\n",
    "# Compile graph\n",
    "orchestrator_app = workflow.compile()\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c366fc",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74848e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Functions\n",
    "#################################################\n",
    "def test_knowledge_agent(query: str):\n",
    "    \"\"\"Test the knowledge agent with a query.\"\"\"\n",
    "    print(f\"\\n--- Testing Knowledge Agent with query: {query} ---\")\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"search_results\": [],\n",
    "        \"response\": \"\",\n",
    "        \"error\": None,\n",
    "        \"account_types\": [],\n",
    "        \"intent\": None\n",
    "    }\n",
    "    try:\n",
    "        result = knowledge_agent.invoke(initial_state)\n",
    "        print(\"\\n--- Knowledge Agent Result ---\")\n",
    "        print(f\"Response: {result['response']}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"response\": f\"Error: {e}\", \"error\": str(e)}\n",
    "def test_card_agent(action: str, card_number: str, parameters: dict = None):\n",
    "    \"\"\"Test the card agent with specified action and parameters.\"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "    print(f\"\\n--- Testing Card Agent: {action} for card {card_number} ---\")\n",
    "    initial_state = {\n",
    "        \"action\": action,\n",
    "        \"card_number\": card_number,\n",
    "        \"parameters\": parameters,\n",
    "        \"api_response\": None,\n",
    "        \"confirmation_message\": \"\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    try:\n",
    "        result = card_agent_app.invoke(initial_state)\n",
    "        print(\"\\n--- Card Agent Result ---\")\n",
    "        print(f\"Confirmation: {result.get('confirmation_message')}\")\n",
    "        if result.get('error'):\n",
    "            print(f\"Error: {result.get('error')}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"confirmation_message\": f\"Error: {e}\", \"error\": str(e)}\n",
    "def test_orchestrator(query: str):\n",
    "    \"\"\"Test the orchestrator with a user query.\"\"\"\n",
    "    print(f\"\\n--- Testing Orchestrator with query: {query} ---\")\n",
    "    initial_state = {\n",
    "        \"user_query\": query,\n",
    "        \"intent\": \"unknown\",\n",
    "        \"card_action_details\": None,\n",
    "        \"knowledge_agent_response\": None,\n",
    "        \"card_agent_response\": None,\n",
    "        \"final_response\": \"\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    try:\n",
    "        result = orchestrator_app.invoke(initial_state)\n",
    "        print(\"\\n--- Orchestrator Result ---\")\n",
    "        print(f\"Intent: {result['intent']}\")\n",
    "        print(f\"Final Response: {result['final_response']}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"final_response\": f\"Error: {e}\", \"error\": str(e)}\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08dad6",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "#################################################\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=====================================\")\n",
    "    print(\"FINANCIAL AGENTS SYSTEM - MERGED DEMO\")\n",
    "    print(\"=====================================\\n\")\n",
    "    # Test Knowledge Agent\n",
    "    print(\"\\n----- KNOWLEDGE AGENT DEMO -----\\n\")\n",
    "    knowledge_queries = [\n",
    "        \"What is an HSA account?\",\n",
    "        \"What's the contribution limit for FSA in 2024?\",\n",
    "        \"How do prepaid healthcare cards work?\"\n",
    "    ]\n",
    "    for query in knowledge_queries:\n",
    "        test_knowledge_agent(query)\n",
    "    # Test Card Agent\n",
    "    print(\"\\n----- CARD AGENT DEMO -----\\n\")\n",
    "    test_card_agent(\"activate\", \"1234\", {\"cvv\": \"123\", \"expiryDate\": \"12/25\"})\n",
    "    test_card_agent(\"deactivate\", \"5678\", {\"reason\": \"Lost card\"})\n",
    "    # Test Orchestrator\n",
    "    print(\"\\n----- ORCHESTRATOR DEMO -----\\n\")\n",
    "    orchestrator_queries = [\n",
    "        \"What are the benefits of an HSA account?\",\n",
    "        \"Activate my card ending in 1234 with CVV 123\",\n",
    "        \"What's the weather today?\"\n",
    "    ]\n",
    "    for query in orchestrator_queries:\n",
    "        test_orchestrator(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ecd88",
   "metadata": {},
   "source": [
    "## Vector DB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Vector DB Setup ---\n",
    "def load_data_for_vectorization():\n",
    "    \"\"\"\n",
    "    Load financial and healthcare data for vector db ingestion\n",
    "    \"\"\"\n",
    "    data_sources = []\n",
    "    # Load accounts data\n",
    "    accounts_file = os.path.join(DATA_DIR, 'synthetic_healthcare_accounts.csv')\n",
    "    if os.path.exists(accounts_file):\n",
    "        logger.info(f\"Loading accounts data from {accounts_file}\")\n",
    "        try:\n",
    "            accounts_df = pd.read_csv(accounts_file)\n",
    "            accounts_text = accounts_df.to_csv(index=False)\n",
    "            data_sources.append({\n",
    "                \"content\": accounts_text,\n",
    "                \"metadata\": {\"source\": \"healthcare_accounts\"}\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load accounts data: {e}\")\n",
    "    # Load transactions data\n",
    "    transactions_file = os.path.join(DATA_DIR, 'synthetic_healthcare_transactions.csv')\n",
    "    if os.path.exists(transactions_file):\n",
    "        logger.info(f\"Loading transactions data from {transactions_file}\")\n",
    "        try:\n",
    "            transactions_df = pd.read_csv(transactions_file)\n",
    "            # Take a sample if it's too large\n",
    "            if len(transactions_df) > 10000:\n",
    "                transactions_df = transactions_df.sample(10000)\n",
    "            transactions_text = transactions_df.to_csv(index=False)\n",
    "            data_sources.append({\n",
    "                \"content\": transactions_text,\n",
    "                \"metadata\": {\"source\": \"healthcare_transactions\"}\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load transactions data: {e}\")\n",
    "    # Load product data\n",
    "    products_file = os.path.join(DATA_DIR, 'synthetic_healthcare_products.json')\n",
    "    if os.path.exists(products_file):\n",
    "        logger.info(f\"Loading products data from {products_file}\")\n",
    "        try:\n",
    "            with open(products_file, 'r') as f:\n",
    "                products_data = json.load(f)\n",
    "                # Process each product separately for better chunks\n",
    "                for product in products_data.get(\"products\", []):\n",
    "                    product_text = json.dumps(product, indent=2)\n",
    "                    data_sources.append({\n",
    "                        \"content\": product_text,\n",
    "                        \"metadata\": {\n",
    "                            \"source\": \"healthcare_products\",\n",
    "                            \"product_id\": product.get(\"id\", \"\"),\n",
    "                            \"product_name\": product.get(\"name\", \"\")\n",
    "                        }\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load products data: {e}\")\n",
    "    # Load plans data\n",
    "    plans_file = os.path.join(DATA_DIR, 'synthetic_healthcare_plans.json')\n",
    "    if os.path.exists(plans_file):\n",
    "        logger.info(f\"Loading plans data from {plans_file}\")\n",
    "        try:\n",
    "            with open(plans_file, 'r') as f:\n",
    "                plans_data = json.load(f)\n",
    "                plans_text = json.dumps(plans_data, indent=2)\n",
    "                data_sources.append({\n",
    "                    \"content\": plans_text,\n",
    "                    \"metadata\": {\"source\": \"healthcare_plans\"}\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load plans data: {e}\")\n",
    "    return data_sources\n",
    "def create_chunks(data_sources):\n",
    "    \"\"\"\n",
    "    Create optimally sized chunks from the data sources\n",
    "    \"\"\"\n",
    "    # Constants from the instruction prompt\n",
    "    CHUNK_SIZE = 600\n",
    "    CHUNK_OVERLAP = 90  # 15% of chunk size\n",
    "    logger.info(f\"Creating chunks with size={CHUNK_SIZE}, overlap={CHUNK_OVERLAP}\")\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    all_chunks = []\n",
    "    # Process each data source\n",
    "    for source in data_sources:\n",
    "        content = source[\"content\"]\n",
    "        metadata = source[\"metadata\"]\n",
    "        # Split the text into chunks\n",
    "        texts = text_splitter.split_text(content)\n",
    "        # Create documents for each chunk\n",
    "        for i, text in enumerate(texts):\n",
    "            # Enrich metadata with chunk information\n",
    "            chunk_metadata = metadata.copy()\n",
    "            chunk_metadata[\"chunk_id\"] = i\n",
    "            chunk_metadata[\"chunk_count\"] = len(texts)\n",
    "            all_chunks.append({\"text\": text, \"metadata\": chunk_metadata})\n",
    "    logger.info(f\"Created {len(all_chunks)} chunks from {len(data_sources)} data sources\")\n",
    "    return all_chunks\n",
    "def get_embedding_client():\n",
    "    \"\"\"\n",
    "    Get the OpenAI embeddings client\n",
    "    \"\"\"\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=EMBEDDING_MODEL,\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize embeddings client: {e}\")\n",
    "        return None\n",
    "def get_vector_store():\n",
    "    \"\"\"\n",
    "    Get or create the ChromaDB vector store with our healthcare financial data\n",
    "    \"\"\"\n",
    "    # Check if we have a flag file indicating the vector store has been populated\n",
    "    flag_file = os.path.join(DATA_DIR, 'vector_store_populated.flag')\n",
    "    # Get embeddings client\n",
    "    embeddings = get_embedding_client()\n",
    "    if not embeddings:\n",
    "        logger.error(\"Cannot get vector store - embeddings client initialization failed\")\n",
    "        return None\n",
    "    # Initialize the vector store\n",
    "    try:\n",
    "        vector_store = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=CHROMA_PERSIST_DIRECTORY if USE_PERSISTENT else None,\n",
    "            client_settings=chromadb.config.Settings(\n",
    "                chroma_api_impl=\"duckdb+parquet\",\n",
    "                chroma_server_host=CHROMA_HOST if not USE_PERSISTENT else None,\n",
    "                chroma_server_http_port=CHROMA_PORT if not USE_PERSISTENT else None,\n",
    "                anonymized_telemetry=False\n",
    "            )\n",
    "        )\n",
    "        # If flag exists, return the existing vector store\n",
    "        if os.path.exists(flag_file):\n",
    "            logger.info(\"Using existing vector store\")\n",
    "            return vector_store\n",
    "        # Otherwise, populate the vector store\n",
    "        logger.info(\"Populating vector store with healthcare financial data\")\n",
    "        # Load and chunk data\n",
    "        data_sources = load_data_for_vectorization()\n",
    "        chunks = create_chunks(data_sources)\n",
    "        # Populate vector store with chunks\n",
    "        for chunk in chunks:\n",
    "            vector_store.add_texts(\n",
    "                texts=[chunk[\"text\"]],\n",
    "                metadatas=[chunk[\"metadata\"]]\n",
    "            )\n",
    "        # Persist if using persistent mode\n",
    "        if USE_PERSISTENT:\n",
    "            vector_store.persist()\n",
    "        # Create flag file\n",
    "        with open(flag_file, 'w') as f:\n",
    "            f.write(\"Vector store populated on \" + pd.Timestamp.now().isoformat())\n",
    "        logger.info(f\"Vector store populated with {len(chunks)} chunks\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize vector store: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d64d4d",
   "metadata": {},
   "source": [
    "## Initialize other CardAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9919b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53f9cf1",
   "metadata": {},
   "source": [
    "## Invoke with the prepared CardAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75656942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Utilities\n",
    "\n",
    "The following functions provide detailed debugging output for each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_knowledge_retrieval(query):\n",
    "    \"\"\"Debug the knowledge retrieval process step by step.\"\"\"\n",
    "    print(f\"\\n=== DEBUGGING KNOWLEDGE RETRIEVAL FOR: '{query}' ===\\n\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state = {\n",
    "        \"query\": query,\n",
    "        \"search_results\": [],\n",
    "        \"response\": \"\",\n",
    "        \"error\": None,\n",
    "        \"account_types\": [],\n",
    "        \"intent\": None\n",
    "    }\n",
    "    \n",
    "    # Extract account types\n",
    "    account_types = []\n",
    "    for account_type in [\"HSA\", \"FSA\", \"Health Savings Account\", \"Flexible Spending Account\", \n",
    "                       \"Dependent Care\", \"Prepaid\", \"Health Care Spend\"]:\n",
    "        if account_type.lower() in query.lower():\n",
    "            short_type = account_type\n",
    "            if account_type == \"Health Savings Account\":\n",
    "                short_type = \"HSA\"\n",
    "            elif account_type == \"Flexible Spending Account\":\n",
    "                short_type = \"FSA\"\n",
    "            \n",
    "            if short_type not in account_types:\n",
    "                account_types.append(short_type)\n",
    "    \n",
    "    print(f\"Detected account types: {account_types if account_types else 'None'}\")\n",
    "    \n",
    "    # Get vector store\n",
    "    print(\"\\nInitializing vector store...\")\n",
    "    vector_store = get_vector_store()\n",
    "    if vector_store:\n",
    "        print(\"✓ Vector store initialized successfully\")\n",
    "    else:\n",
    "        print(\"✗ Vector store initialization failed, will use mock data\")\n",
    "    \n",
    "    # Run intent classification\n",
    "    print(\"\\nClassifying query intent...\")\n",
    "    intent = classify_intent(query)\n",
    "    print(f\"Classified intent: {intent}\")\n",
    "    \n",
    "    # Run knowledge retrieval\n",
    "    print(\"\\nRetrieving knowledge...\")\n",
    "    updated_state = retrieve_knowledge(state)\n",
    "    \n",
    "    # Print search results\n",
    "    print(f\"\\nFound {len(updated_state['search_results'])} search results:\")\n",
    "    for i, result in enumerate(updated_state['search_results']):\n",
    "        print(f\"\\nResult {i+1}:\")\n",
    "        print(f\"Source: {result['source']}\")\n",
    "        if result['product_name']:\n",
    "            print(f\"Product: {result['product_name']}\")\n",
    "        print(f\"Text: {result['text'][:100]}...\")\n",
    "    \n",
    "    # Generate response\n",
    "    print(\"\\nGenerating response...\")\n",
    "    final_state = generate_response(updated_state)\n",
    "    \n",
    "    print(\"\\n=== FINAL RESPONSE ===\\n\")\n",
    "    print(final_state['response'])\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "def debug_card_action(action, card_number, parameters=None):\n",
    "    \"\"\"Debug card action execution step by step.\"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "        \n",
    "    print(f\"\\n=== DEBUGGING CARD ACTION: {action} for card {card_number} ===\\n\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state = {\n",
    "        \"action\": action,\n",
    "        \"card_number\": card_number,\n",
    "        \"parameters\": parameters,\n",
    "        \"api_response\": None,\n",
    "        \"confirmation_message\": \"\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    print(f\"Card API URL: {CARD_API_BASE_URL}/{action}\")\n",
    "    print(f\"Payload: {{'cardLastFour': '{card_number}', **{parameters}}}\")\n",
    "    \n",
    "    # Mock the API call for debugging\n",
    "    print(\"\\nMocking API call for debugging purposes...\")\n",
    "    mock_result = {\n",
    "        \"success\": True,\n",
    "        \"message\": f\"Card {action} request processed for card ending in {card_number}\",\n",
    "        \"card\": {\n",
    "            \"lastFour\": card_number,\n",
    "            \"status\": \"ACTIVE\" if action == \"activate\" else \"INACTIVE\",\n",
    "            \"type\": \"HSA\",\n",
    "            \"expiryDate\": parameters.get(\"expiryDate\", \"12/25\")\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Execute card action\n",
    "    print(\"\\nExecuting card action...\")\n",
    "    # Normally we'd call execute_card_action, but we'll use our mock for safety\n",
    "    result = {\n",
    "        **state,\n",
    "        \"api_response\": mock_result,\n",
    "        \"confirmation_message\": mock_result.get(\"message\"),\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== RESULT ===\\n\")\n",
    "    print(f\"Confirmation: {result['confirmation_message']}\")\n",
    "    print(f\"API Response: {result['api_response']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def debug_orchestrator(query):\n",
    "    \"\"\"Debug the orchestrator's intent classification and routing.\"\"\"\n",
    "    print(f\"\\n=== DEBUGGING ORCHESTRATOR FOR QUERY: '{query}' ===\\n\")\n",
    "    \n",
    "    # Initialize state\n",
    "    state = {\n",
    "        \"user_query\": query,\n",
    "        \"intent\": \"unknown\",\n",
    "        \"card_action_details\": None,\n",
    "        \"knowledge_agent_response\": None,\n",
    "        \"card_agent_response\": None,\n",
    "        \"final_response\": \"\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    # Classify intent\n",
    "    print(\"Classifying intent...\")\n",
    "    classified_state = classify_intent(state)\n",
    "    print(f\"Classified intent: {classified_state['intent']}\")\n",
    "    \n",
    "    if classified_state['intent'] == 'card_action':\n",
    "        print(\"\\nCard action details:\")\n",
    "        details = classified_state['card_action_details']\n",
    "        if details:\n",
    "            print(f\"  Action: {details['action']}\")\n",
    "            print(f\"  Card Number: {details['card_number']}\")\n",
    "            print(f\"  Parameters: {details['parameters']}\")\n",
    "        else:\n",
    "            print(\"  No card details extracted\")\n",
    "    \n",
    "    # Determine routing\n",
    "    print(\"\\nDetermining routing...\")\n",
    "    route = decide_route(classified_state)\n",
    "    print(f\"Route decision: {route}\")\n",
    "    \n",
    "    # Execute the appropriate action based on route\n",
    "    if route == \"knowledge\":\n",
    "        print(\"\\nRouting to Knowledge Agent...\")\n",
    "        # Just call for a simple response for debugging\n",
    "        response = handle_query(query)\n",
    "        print(f\"\\nKnowledge Response: {response}\")\n",
    "        classified_state['knowledge_agent_response'] = response\n",
    "    elif route == \"card_action\" and classified_state['card_action_details']:\n",
    "        print(\"\\nRouting to Card Agent...\")\n",
    "        details = classified_state['card_action_details']\n",
    "        # Use our mock function\n",
    "        mock_result = debug_card_action(details['action'], details['card_number'], details['parameters'])\n",
    "        classified_state['card_agent_response'] = mock_result['confirmation_message']\n",
    "    \n",
    "    # Format the final response\n",
    "    print(\"\\nFormatting final response...\")\n",
    "    final_state = format_final_response(classified_state)\n",
    "    \n",
    "    print(\"\\n=== FINAL RESPONSE ===\\n\")\n",
    "    print(final_state['final_response'])\n",
    "    \n",
    "    return final_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Test the components with your own queries and scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Knowledge Agent\n",
    "debug_knowledge_retrieval(\"What are the contribution limits for HSA accounts in 2024?\")\n",
    "\n",
    "# Test Card Agent\n",
    "debug_card_action(\"activate\", \"1234\", {\"cvv\": \"123\", \"expiryDate\": \"05/26\"})\n",
    "\n",
    "# Test Orchestrator with knowledge question\n",
    "debug_orchestrator(\"How do FSA accounts work?\")\n",
    "\n",
    "# Test Orchestrator with card action\n",
    "debug_orchestrator(\"I need to activate my card ending in 5678 with CVV 456\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
